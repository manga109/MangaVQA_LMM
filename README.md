# MangaVQA and MangaLMM

This is the repository that contains source code for the [MangaVQA and MangaLMM project website](https://atsumiyai.github.io/mangalmm_vqa/).

## Project Description

We present **MangaVQA**, a benchmark of 526 manually constructed questionâ€“answer pairs designed to evaluate an LMM's ability to accurately answer targeted, factual questions grounded in both visual and textual context. We also develop **MangaLMM**, a manga-specialized version of Qwen2.5-VL, finetuned to jointly address both VQA and OCR tasks.

## Citation

If you find MangaVQA and MangaLMM useful for your work please cite:

```bibtex
@inproceedings{baek2025mangavqa,
  author    = {Baek, Jeonghun and Egashira, Kazuki and Onohara, Shota and Miyai, Atsuyuki and Imajuku, Yuki and Ikuta, Hikaru and Aizawa, Kiyoharu},
  title     = {MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal Manga Understanding},
  booktitle = {Findings of the Association for Computational Linguistics: EACL 2026},
  year      = {2026},
}
```

## Links

- [Paper](https://arxiv.org/abs/2505.20298)
- [Code](https://github.com/manga109/MangaLMM)
- [Dataset](https://huggingface.co/collections/hal-utokyo/mangavqa-and-mangaocr)
- [Model](https://huggingface.co/hal-utokyo/MangaLMM)

# Website License

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.

This website is inspired by and references [Nerfies](https://github.com/nerfies/nerfies.github.io).
